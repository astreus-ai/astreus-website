---
title: Quick Start Guide
---

This guide will help you get started with Astreus by setting up your development environment and creating your first AI agent with **streaming capabilities**.

## Installation

Install Astreus via npm:

```bash
npm install @astreus-ai/astreus
```

Or using yarn:

```bash
yarn add @astreus-ai/astreus
```

## Environment Setup

Create a `.env` file in your project root with your API keys:

```
# OpenAI API Key (Required for OpenAI provider)
OPENAI_API_KEY=your_openai_api_key

# Database Configuration
DATABASE_TYPE=sqlite  # or postgresql
DATABASE_PATH=./astreus.db  # Only for SQLite
# DATABASE_URL=postgresql://user:password@localhost:5432/astreus  # For PostgreSQL

# Ollama Configuration (Optional)
# OLLAMA_BASE_URL=http://localhost:11434

# Logging
LOG_LEVEL=info  # debug, info, warn, error
```

## Creating Your First Agent

With Astreus 0.1.9+, everything revolves around the **Agent**. Create a file named `my-agent.js` (or `.ts` if using TypeScript):

```typescript
import { 
  createAgent, 
  createProvider,
  createMemory,
  createDatabase,
  logger
} from '@astreus-ai/astreus';

async function main() {
  try {
    // Initialize the database
    const db = await createDatabase();
    
    // Create memory instance
    const memory = await createMemory({
      database: db,
      tableName: "conversations"
    });

    // Configure your provider
    const provider = createProvider({
      type: 'openai',
      model: 'gpt-4o-mini'  // Fast and affordable option
    });

    // Create an agent - everything you need in one place!
    const agent = await createAgent({
      name: 'MyFirstAgent',
      description: 'A helpful AI assistant with streaming capabilities',
      provider: provider,
      memory: memory,
      systemPrompt: "You are a friendly and helpful AI assistant. Answer questions concisely and accurately."
    });

    // ðŸš€ Basic chat (non-streaming)
    console.log('=== Basic Chat ===');
    const response = await agent.chat({
      message: "Hello! What can you do for me?",
      sessionId: "session-1"
    });
    console.log('Agent:', response);

    // âš¡ Streaming chat (real-time responses)
    console.log('\n=== Streaming Chat ===');
    const streamResponse = await agent.streamChat({
      message: "Tell me about the benefits of AI in 3 points",
      sessionId: "session-1",
      onChunk: (chunk) => {
        process.stdout.write(chunk); // Print each chunk as it arrives
      }
    });
    console.log('\nâœ… Streaming complete!');

    // ðŸ“Š Check session history
    console.log('\n=== Session History ===');
    const history = await agent.getHistory("session-1");
    console.log(`Found ${history.length} messages in session`);

    // ðŸ“‹ List all sessions
    console.log('\n=== All Sessions ===');
    const sessions = await agent.listSessions();
    sessions.forEach(session => {
      console.log(`Session: ${session.sessionId} (${session.messageCount} messages)`);
    });
    
  } catch (error) {
    logger.error('Error:', error);
  }
}

main();
```

Run your agent:

```bash
node my-agent.js
```

## Real-Time Streaming Example

Here's how to implement real-time streaming in a web application:

```typescript
import { createAgent, createProvider, createMemory, createDatabase } from '@astreus-ai/astreus';
import WebSocket from 'ws';

// WebSocket server for real-time streaming
const wss = new WebSocket.Server({ port: 8080 });

async function setupAgent() {
  const db = await createDatabase();
  const memory = await createMemory({ database: db });
  const provider = createProvider({ type: 'openai', model: 'gpt-4o-mini' });

  return await createAgent({
    name: 'StreamingAgent',
    provider: provider,
    memory: memory,
    systemPrompt: "You are a helpful assistant that provides detailed, informative responses."
  });
}

wss.on('connection', async (ws) => {
  const agent = await setupAgent();
  
  ws.on('message', async (data) => {
    const { message, sessionId } = JSON.parse(data.toString());
    
    // Stream response to client in real-time
    await agent.streamChat({
      message,
      sessionId,
      onChunk: (chunk) => {
        ws.send(JSON.stringify({ 
          type: 'chunk', 
          content: chunk 
        }));
      }
    });
    
    // Signal completion
    ws.send(JSON.stringify({ type: 'complete' }));
  });
});

console.log('WebSocket server running on ws://localhost:8080');
```

## Adding Custom Tools

Enhance your agent with custom capabilities:

```typescript
import { createAgent, createProvider, createMemory, createDatabase, Plugin } from '@astreus-ai/astreus';

// Create a weather tool
const weatherTool: Plugin = {
  name: "get_weather",
  description: "Get current weather information for a city",
  parameters: {
    city: {
      type: "string",
      description: "The city name to get weather for"
    }
  },
  execute: async (params) => {
    // In a real app, you'd call a weather API
    return {
      success: true,
      output: `The weather in ${params.city} is sunny with 22Â°C`
    };
  }
};

async function main() {
  const db = await createDatabase();
  const memory = await createMemory({ database: db });
  const provider = createProvider({ type: 'openai', model: 'gpt-4o-mini' });

  // Create agent with tools
  const agent = await createAgent({
    name: 'WeatherAgent',
    provider: provider,
    memory: memory,
    tools: [weatherTool], // Add tools here
    systemPrompt: "You are a helpful assistant that can provide weather information. Use the get_weather tool when asked about weather."
  });

  // Add more tools dynamically
  const calculatorTool: Plugin = {
    name: "calculator",
    description: "Perform mathematical calculations",
    parameters: {
      expression: {
        type: "string",
        description: "Mathematical expression to evaluate"
      }
    },
    execute: async (params) => {
      try {
        // Use a proper math parser in production
        const result = Function(`'use strict'; return (${params.expression})`)();
        return { success: true, output: `Result: ${result}` };
      } catch (error) {
        return { success: false, error: error.message };
      }
    }
  };

  // Add tool to existing agent
  agent.addTool(calculatorTool);

  // Test the tools
  console.log('Available tools:', agent.getAvailableTools());

  // Chat with tool usage
  const response = await agent.streamChat({
    message: "What's the weather in London and what's 15 * 24?",
    sessionId: "tools-session",
    onChunk: (chunk) => process.stdout.write(chunk)
  });
}

main();
```

## Memory and Session Management

Access and manage conversation history:

```typescript
async function memoryExample() {
  const agent = await setupAgent(); // Your agent setup

  // Add custom memory entries
  await agent.addToMemory({
    sessionId: "custom-session",
    role: 'system',
    content: "User prefers detailed explanations",
    metadata: { preference: 'detailed' }
  });

  // Get conversation history
  const history = await agent.getHistory("custom-session", 10);
  console.log('Recent messages:', history);

  // Clear a session
  await agent.clearHistory("old-session");

  // List all sessions with metadata
  const sessions = await agent.listSessions(20);
  sessions.forEach(session => {
    console.log(`Session: ${session.sessionId}`);
    console.log(`Last message: ${session.lastMessage}`);
    console.log(`Messages: ${session.messageCount}`);
    console.log(`Last activity: ${session.lastActivity}`);
  });

  // Access memory directly for advanced operations
  const memory = agent.config.memory;
  const searchResults = await memory.searchByText("weather", 5);
  console.log('Weather-related messages:', searchResults);
}
```

## Advanced Configuration

Access all components through the agent:

```typescript
async function advancedExample() {
  const agent = await setupAgent();

  // Access provider
  const provider = agent.getProvider();
  if (provider) {
    console.log('Available models:', provider.listModels());
    console.log('Current model:', agent.getModel().name);
  }

  // Access database directly
  const db = agent.config.database;
  const customQuery = await db.knex('memories')
    .where('agentId', agent.id)
    .count('* as total');
  console.log('Total memories:', customQuery[0].total);

  // Access memory for advanced operations
  const memory = agent.config.memory;
  const agentMemories = await memory.getByAgent(agent.id, 50);
  console.log(`Agent has ${agentMemories.length} memories`);

  // Switch models dynamically
  const newModel = provider?.getModel('gpt-4');
  if (newModel) {
    agent.config.model = newModel;
    console.log('Switched to GPT-4');
  }
}
```

## Next Steps

Now that you have a working agent with streaming capabilities:

1. **Explore Concepts**: Learn about [Agents](/docs/concepts/agents), [Memory](/docs/concepts/memory), and [Chat](/docs/concepts/chat)
2. **Add Plugins**: Check out [Custom Plugins](/docs/guides/custom-plugins) to extend functionality
3. **Setup RAG**: Follow the [RAG Setup Guide](/docs/guides/rag-setup) for document search capabilities
4. **Production Deployment**: Configure PostgreSQL and proper error handling for production use

## Troubleshooting

**Streaming not working?**
- Ensure you're using OpenAI provider with a valid API key
- Check that `onChunk` callback is properly defined
- Verify your model supports streaming (most OpenAI models do)

**Memory issues?**
- Check database connection and table creation
- Verify session IDs are consistent
- Use `agent.getHistory()` to debug conversation flow

**Tool not being called?**
- Ensure tool description clearly explains when to use it
- Check parameter definitions match expected input
- Use detailed system prompts that mention available tools 