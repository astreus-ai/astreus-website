---
title: Agents
---

Agents are the **heart of the Astreus framework**. An agent represents an AI assistant that provides a **unified interface** to all framework capabilities including streaming chat, memory management, tool execution, and more.

## Agent-Centric Architecture

With Astreus 0.1.9+, everything revolves around the **Agent**. Instead of managing separate components, you access everything through the agent:

```typescript
// âœ… New Agent-Centric Approach
const agent = await createAgent({
  name: 'MyAgent',
  provider: myProvider,
  memory: myMemory
});

// All operations through agent methods
await agent.streamChat({ message: "Hello!" });
const history = await agent.getHistory("session-1");
const sessions = await agent.listSessions();
const provider = agent.getProvider();
const memory = agent.config.memory;
const database = agent.config.database;
```

## Core Agent Capabilities

Each Astreus agent provides:

- **ðŸš€ Streaming Chat**: Real-time responses with `agent.streamChat()`
- **ðŸ’¬ Standard Chat**: Non-streaming responses with `agent.chat()`
- **ðŸ§  Memory Management**: Session-based conversation history
- **ðŸ“‹ Session Tracking**: List and manage conversation sessions
- **ðŸ”Œ Tool Integration**: Add and use custom tools
- **ðŸ—„ï¸ Database Access**: Direct access to underlying storage
- **ðŸŽ¯ Provider Flexibility**: Switch models and providers dynamically

## Creating an Agent

Use the `createAgent` function to create a fully-featured agent:

```typescript
import { 
  createAgent, 
  createProvider,
  createMemory,
  createDatabase
} from '@astreus-ai/astreus';

async function createMyAgent() {
  // Initialize the database
  const db = await createDatabase();
  
  // Create memory instance
  const memory = await createMemory({
    database: db,
    tableName: "conversations",
    maxEntries: 200
  });

  // Configure your provider
  const provider = createProvider({
    type: 'openai',
    model: 'gpt-4o-mini',
    apiKey: process.env.OPENAI_API_KEY
  });

  // Create an agent with all capabilities
  const agent = await createAgent({
    name: 'MyAssistant',
    description: 'A helpful AI assistant with streaming capabilities',
    provider: provider,
    memory: memory,
    systemPrompt: "You are a helpful AI assistant that provides detailed, accurate responses.",
    tools: [customTool1, customTool2] // Optional tools
  });

  return agent;
}
```

## Streaming Chat

The agent provides built-in streaming capabilities for real-time responses:

```typescript
// Real-time streaming chat
const response = await agent.streamChat({
  message: "Explain quantum computing in simple terms",
  sessionId: "physics-chat",
  systemPrompt: "You are a physics teacher. Explain concepts clearly.",
  temperature: 0.7,
  maxTokens: 1000,
  metadata: { topic: 'physics', level: 'beginner' },
  onChunk: (chunk) => {
    // Send chunk to frontend in real-time
    console.log('Chunk:', chunk);
    websocket.send(JSON.stringify({ type: 'chunk', content: chunk }));
  }
});

console.log('Full response:', response);
```

## Standard Chat

For non-streaming scenarios, use the standard chat method:

```typescript
// Standard chat (no streaming)
const response = await agent.chat({
  message: "What's the weather like?",
  sessionId: "weather-chat",
  temperature: 0.5,
  maxTokens: 500,
  metadata: { type: 'weather_query' }
});

console.log('Response:', response);
```

## Memory and Session Management

Agents provide direct access to conversation history and session management:

```typescript
// Get conversation history
const history = await agent.getHistory("session-123", 10);
console.log(`Found ${history.length} messages`);

// Add custom memory entries
await agent.addToMemory({
  sessionId: "session-123",
  role: 'system',
  content: "User prefers technical explanations",
  metadata: { preference: 'technical' }
});

// List all sessions
const sessions = await agent.listSessions(20);
sessions.forEach(session => {
  console.log(`Session: ${session.sessionId}`);
  console.log(`Messages: ${session.messageCount}`);
  console.log(`Last activity: ${session.lastActivity}`);
});

// Clear a session
await agent.clearHistory("old-session");
```

## Tool Integration

Add and manage tools directly through the agent:

```typescript
// Define a custom tool
const weatherTool = {
  name: "get_weather",
  description: "Get current weather for a city",
  parameters: {
    city: { type: "string", description: "City name" }
  },
  execute: async (params) => {
    // Call weather API
    return { success: true, output: `Weather in ${params.city}: Sunny, 22Â°C` };
  }
};

// Add tool to agent
agent.addTool(weatherTool);

// Check available tools
const tools = agent.getAvailableTools();
console.log('Available tools:', tools);

// Tools are automatically used during chat
const response = await agent.streamChat({
  message: "What's the weather in London?",
  sessionId: "weather-session",
  onChunk: (chunk) => console.log(chunk)
});
```

## Provider and Model Access

Access and manage the underlying provider and model:

```typescript
// Get provider
const provider = agent.getProvider();
if (provider) {
  console.log('Available models:', provider.listModels());
  console.log('Provider type:', provider.type);
}

// Get current model
const model = agent.getModel();
console.log('Current model:', model.name);

// Switch models dynamically
const gpt4 = provider?.getModel('gpt-4');
if (gpt4) {
  agent.config.model = gpt4;
  console.log('Switched to GPT-4');
}
```

## Database and Memory Access

Access underlying storage systems for advanced operations:

```typescript
// Direct database access
const database = agent.config.database;
const customQuery = await database.knex('memories')
  .where('agentId', agent.id)
  .andWhere('sessionId', 'like', '%important%')
  .orderBy('timestamp', 'desc');

// Direct memory access
const memory = agent.config.memory;

// Search by text
const textResults = await memory.searchByText("machine learning", 5);

// Search by embedding (if enabled)
const embedding = [0.1, 0.2, 0.3, 0.4, 0.5]; // 1536-dimensional vector for OpenAI
const similarResults = await memory.searchByEmbedding(embedding, 5, 0.8);

// Get all memories for this agent
const allMemories = await memory.getByAgent(agent.id, 100);
```

## Agent Configuration Options

| Option | Type | Description | Required |
|--------|------|-------------|----------|
| `name` | string | Agent name | No (defaults to "Assistant") |
| `description` | string | Agent description | No |
| `provider` | ProviderInstance | LLM provider | Yes (or model) |
| `model` | ProviderModel | Specific model instance | Yes (or provider) |
| `memory` | MemoryInstance | Memory for conversations | Yes |
| `database` | DatabaseInstance | Database for persistence | No |
| `systemPrompt` | string | Default system instructions | No |
| `tools` | Plugin[] | Array of tools/plugins | No |
| `plugins` | PluginInstance[] | Plugin instances | No |
| `rag` | RAGInstance | RAG system (auto-creates tools) | No |
| `chat` | ChatInstance | Chat manager instance | No |

## Agent with RAG Capabilities

When you provide a RAG instance, the agent automatically gains document search tools:

```typescript
import { createAgent, createRAG, RAGType, parsePDF } from '@astreus-ai/astreus';

async function createRAGAgent() {
  const db = await createDatabase();
  const memory = await createMemory({ database: db });
  const provider = createProvider({ type: 'openai', model: 'gpt-4o-mini' });

  // Create RAG system
  const rag = await createRAG({
    type: RAGType.VECTOR,
    database: db,
    provider: provider,
    chunkSize: 1000,
    chunkOverlap: 200
  });

  // Add documents
  const pdfResult = await parsePDF('./manual.pdf');
  for (const doc of pdfResult.documents) {
    await rag.addDocument({
      content: doc.content,
      metadata: { source: 'manual', page: doc.metadata.page }
    });
  }

  // Create agent with RAG
  const agent = await createAgent({
    name: 'DocumentAssistant',
    provider: provider,
    memory: memory,
    rag: rag, // Automatically adds RAG tools
    systemPrompt: `You are a helpful assistant with access to documentation. 
Use the rag_search tool to find relevant information when answering questions.`
  });

  // Agent now has RAG tools available
  console.log('RAG tools:', agent.getAvailableTools().filter(t => t.startsWith('rag_')));

  return agent;
}

// Use the RAG agent
const ragAgent = await createRAGAgent();

// Agent automatically searches documents when relevant
const response = await ragAgent.streamChat({
  message: "How do I configure the database?",
  sessionId: "docs-session",
  onChunk: (chunk) => console.log(chunk)
});
```

## Advanced Agent Patterns

### Multi-Model Agent

Switch between models based on task complexity:

```typescript
class SmartAgent {
  private agent: AgentInstance;
  private provider: ProviderInstance;

  constructor(agent: AgentInstance) {
    this.agent = agent;
    this.provider = agent.getProvider()!;
  }

  async smartChat(message: string, sessionId: string) {
    // Use fast model for simple queries
    if (message.length < 50) {
      const fastModel = this.provider.getModel('gpt-4o-mini');
      this.agent.config.model = fastModel;
    } else {
      // Use powerful model for complex queries
      const powerfulModel = this.provider.getModel('gpt-4');
      this.agent.config.model = powerfulModel;
    }

    return await this.agent.streamChat({
      message,
      sessionId,
      onChunk: (chunk) => this.handleChunk(chunk)
    });
  }

  private handleChunk(chunk: string) {
    // Custom chunk processing
    console.log('Processing chunk:', chunk);
  }
}
```

### Agent with Custom Memory Strategy

```typescript
class MemoryAwareAgent {
  private agent: AgentInstance;

  constructor(agent: AgentInstance) {
    this.agent = agent;
  }

  async chatWithContext(message: string, sessionId: string) {
    // Get relevant context from memory
    const memory = this.agent.config.memory;
    const relevantMemories = await memory.searchByText(message, 3);
    
    // Build context-aware system prompt
    const context = relevantMemories
      .map(m => `Previous: ${m.content}`)
      .join('\n');
    
    const systemPrompt = `You are a helpful assistant. Consider this context:
${context}

Respond to the user's current message while being aware of the conversation history.`;

    return await this.agent.streamChat({
      message,
      sessionId,
      systemPrompt,
      onChunk: (chunk) => console.log(chunk)
    });
  }
}
```

## Best Practices

1. **Use Streaming**: Implement `streamChat()` for better user experience
2. **Session Management**: Use consistent session IDs for conversation continuity
3. **Memory Optimization**: Regularly clean old sessions with `clearHistory()`
4. **Tool Organization**: Group related tools and use clear descriptions
5. **Error Handling**: Wrap agent calls in try-catch blocks
6. **Model Selection**: Choose appropriate models for different use cases
7. **System Prompts**: Use specific, clear instructions for better responses

## Migration from Previous Versions

If you're upgrading from earlier Astreus versions:

```typescript
// âŒ Old approach (pre-0.1.9)
const chatManager = await createChat({
  provider: myProvider,
  memory: myMemory
});
const response = await chatManager.chat({
  chatId,
  agentId,
  message,
  provider,
  systemPrompt
});

// âœ… New agent-centric approach (0.1.9+)
const agent = await createAgent({
  name: 'MyAgent',
  provider: myProvider,
  memory: myMemory
});
const response = await agent.streamChat({
  message,
  sessionId,
  systemPrompt,
  onChunk: (chunk) => console.log(chunk)
});
```

The agent-centric approach simplifies development and provides more powerful capabilities while maintaining backward compatibility where possible. 