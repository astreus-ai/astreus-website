---
title: Chat
description: Learn about real-time streaming chat, advanced chat management, and session organization with Astreus's agent-centric approach
---

The **Chat System** in Astreus is **agent-centric** and provides powerful **real-time streaming** capabilities with **advanced chat management**. Instead of managing separate chat managers, everything flows through the agent with built-in session management, chat organization, and metadata support.

## Agent-Centric Chat Architecture

With the enhanced approach, chat functionality is built directly into agents with full chat management:

```typescript
// ✅ Enhanced Agent-Centric Approach with Chat Management
const agent = await createAgent({
  name: 'ChatAgent',
  provider: myProvider,
  memory: myMemory,
  chat: myChatManager // Chat management system
});

// Create structured chats with metadata
const chat = await agent.createChat({
  chatId: "consultation-123",
  title: "Export Regulation Consultation",
  metadata: { type: "business", priority: "high" }
});

// Real-time streaming chat with chat IDs
await agent.streamChatWithId({
  message: "Hello!",
  chatId: "consultation-123",
  onChunk: (chunk) => console.log(chunk)
});

// Standard chat with chat IDs
const response = await agent.chatWithId({
  message: "How are you?",
  chatId: "consultation-123"
});

// Advanced chat management
const chats = await agent.listChats({ status: 'active' });
const stats = await agent.getChatStats();
const searchResults = await agent.searchChats({ query: "export" });

// Legacy session management (still supported)
const sessions = await agent.listSessions();
const history = await agent.getHistory("session-123");
```

## Chat Management

Create, organize, and manage structured chats with metadata and lifecycle management:

### Creating and Managing Chats

```typescript
import { createAgent, createProvider, createMemory, createDatabase, createChat } from '@astreus-ai/astreus';

async function setupChatAgent() {
  const db = await createDatabase();
  const memory = await createMemory({ database: db });
  const chatManager = await createChat({
    database: db,
    memory: memory,
    tableName: "chats",
    maxChats: 100,
    autoGenerateTitles: true
  });
  
  const provider = createProvider({ 
    type: 'openai', 
    model: 'gpt-4o-mini',
    apiKey: process.env.OPENAI_API_KEY
  });

  return await createAgent({
    name: 'ChatManagementAgent',
    provider: provider,
    memory: memory,
    chat: chatManager,
    systemPrompt: "You are a helpful assistant with advanced chat management."
  });
}

const agent = await setupChatAgent();

// Create a new chat with metadata
const chat = await agent.createChat({
  chatId: "support-ticket-456",
  userId: "user-123",
  title: "Technical Support Request",
  metadata: {
    type: "support",
    priority: "high",
    department: "technical",
    language: "en",
    tags: ["bug", "urgent"]
  }
});

// Get chat details
const chatDetails = await agent.getChat("support-ticket-456");
console.log('Chat created:', chatDetails);

// Update chat metadata
await agent.updateChat("support-ticket-456", {
  title: "Resolved: Technical Support Request",
  metadata: { 
    ...chatDetails.metadata, 
    status: "resolved",
    resolvedAt: new Date().toISOString()
  }
});
```

### Chat Organization and Search

```typescript
// List chats with filtering
const activeChats = await agent.listChats({
  userId: "user-123",
  status: 'active',
  limit: 20,
  offset: 0
});

console.log(`Found ${activeChats.length} active chats`);

// Search chats by content
const searchResults = await agent.searchChats({
  query: "technical support",
  userId: "user-123",
  limit: 10
});

console.log(`Found ${searchResults.length} matching chats`);

// Get comprehensive chat statistics
const stats = await agent.getChatStats({
  userId: "user-123"
});

console.log(`Total chats: ${stats.totalChats}`);
console.log(`Active chats: ${stats.activeChats}`);
console.log(`Archived chats: ${stats.archivedChats}`);
console.log(`Total messages: ${stats.totalMessages}`);

// Archive old chats
await agent.archiveChat("old-chat-id");

// Delete unwanted chats permanently
await agent.deleteChat("spam-chat-id");
```

## Real-Time Streaming Chat

The enhanced chat system provides **real-time streaming** with both chat IDs and legacy session support:

### Streaming with Chat IDs (Recommended)

```typescript
// Real-time streaming with chat management
const response = await agent.streamChatWithId({
  message: "Explain machine learning in simple terms",
  chatId: "ml-tutorial-789",
  userId: "student-456",
  temperature: 0.7,
  maxTokens: 1000,
  metadata: { topic: 'education', level: 'beginner' },
  onChunk: (chunk) => {
    // Each chunk arrives in real-time
    process.stdout.write(chunk);
    
    // Send to frontend via WebSocket
    // websocket.send(JSON.stringify({ type: 'chunk', content: chunk }));
  }
});

console.log('\nFull response:', response);
```

### Legacy Session-Based Streaming (Still Supported)

```typescript
// Legacy streaming (for backward compatibility)
const legacyResponse = await agent.streamChat({
  message: "Explain machine learning",
  sessionId: "ml-session",
  onChunk: (chunk) => console.log(chunk)
});
```

### WebSocket Integration with Chat Management

Here's how to integrate streaming with WebSocket for real-time frontend updates with chat management:

```typescript
import WebSocket from 'ws';
import { createAgent, createProvider, createMemory, createDatabase, createChat } from '@astreus-ai/astreus';

// WebSocket server for real-time chat with management
const wss = new WebSocket.Server({ port: 8080 });

async function createAdvancedChatAgent() {
  const db = await createDatabase();
  const memory = await createMemory({ database: db });
  const chatManager = await createChat({ database: db, memory: memory });
  const provider = createProvider({ type: 'openai', model: 'gpt-4o-mini' });

  return await createAgent({
    name: 'WebSocketChatAgent',
    provider: provider,
    memory: memory,
    chat: chatManager,
    systemPrompt: "You are a helpful assistant for real-time chat with advanced management."
  });
}

wss.on('connection', async (ws) => {
  const agent = await createAdvancedChatAgent();
  
  ws.on('message', async (data) => {
    try {
      const { message, chatId, userId, action } = JSON.parse(data.toString());
      
      if (action === 'create_chat') {
        // Create a new chat
        const chat = await agent.createChat({
          chatId,
          userId,
          title: "New Conversation",
          metadata: { createdVia: "websocket" }
        });
        
        ws.send(JSON.stringify({ 
          type: 'chat_created', 
          chat 
        }));
        return;
      }
      
      if (action === 'list_chats') {
        // List user's chats
        const chats = await agent.listChats({ userId, limit: 20 });
        ws.send(JSON.stringify({ 
          type: 'chats_list', 
          chats 
        }));
        return;
      }
      
      // Stream response to client in real-time
      await agent.streamChatWithId({
        message,
        chatId,
        userId,
        metadata: { timestamp: new Date() },
        onChunk: (chunk) => {
          // Send each chunk immediately
          ws.send(JSON.stringify({ 
            type: 'chunk', 
            content: chunk,
            chatId 
          }));
        }
      });
      
      // Signal completion
      ws.send(JSON.stringify({ 
        type: 'complete',
        chatId 
      }));
      
    } catch (error) {
      ws.send(JSON.stringify({ 
        type: 'error', 
        message: error.message 
      }));
    }
  });
});

console.log('Advanced WebSocket chat server running on ws://localhost:8080');
```

## Standard Chat (Non-Streaming)

For scenarios where streaming isn't needed, use the enhanced chat methods:

### Chat with Chat IDs (Recommended)

```typescript
// Standard chat with chat management
const response = await agent.chatWithId({
  message: "What's the capital of France?",
  chatId: "geography-quiz-123",
  userId: "student-456",
  temperature: 0.3,
  maxTokens: 100,
  metadata: { category: 'geography', difficulty: 'easy' }
});

console.log('Response:', response);
```

### Legacy Session-Based Chat (Still Supported)

```typescript
// Legacy chat (for backward compatibility)
const legacyResponse = await agent.chat({
  message: "What's the capital of France?",
  sessionId: "geography-session",
  temperature: 0.3,
  maxTokens: 100,
  metadata: { category: 'geography', difficulty: 'easy' }
});
```

## Session Management

Agents provide built-in session management alongside the new chat management:

### Session Operations

```typescript
// List all sessions for the agent (legacy support)
const sessions = await agent.listSessions(20);
sessions.forEach(session => {
  console.log(`Session: ${session.sessionId}`);
  console.log(`Messages: ${session.messageCount}`);
  console.log(`Last message: ${session.lastMessage}`);
  console.log(`Last activity: ${session.lastActivity}`);
  console.log(`Metadata:`, session.metadata);
});

// Get conversation history (works with both chat IDs and session IDs)
const history = await agent.getHistory("chat-123", 50);
console.log(`Found ${history.length} messages`);

// Add custom memory entries
await agent.addToMemory({
  sessionId: "chat-123", // Can use chat ID as session ID
  role: 'system',
  content: "User prefers technical explanations",
  metadata: { preference: 'technical', timestamp: new Date() }
});

// Clear a session/chat
await agent.clearHistory("old-session");
```

### Session Metadata

Sessions automatically track metadata and can be extended with custom data:

```typescript
// Chat with custom metadata
await agent.streamChat({
  message: "Help me with Python programming",
  sessionId: "python-help",
  metadata: {
    language: 'python',
    skill_level: 'intermediate',
    topic: 'programming',
    user_id: 'user123'
  },
  onChunk: (chunk) => console.log(chunk)
});

// Metadata is automatically stored and can be retrieved
const sessions = await agent.listSessions();
const pythonSession = sessions.find(s => s.sessionId === 'python-help');
console.log('Session metadata:', pythonSession?.metadata);
```

## Advanced Chat Patterns

### Context-Aware Conversations

Use memory search to provide context-aware responses:

```typescript
class ContextualAgent {
  private agent: AgentInstance;

  constructor(agent: AgentInstance) {
    this.agent = agent;
  }

  async contextualChat(message: string, sessionId: string) {
    // Search for relevant context from memory
    const memory = this.agent.config.memory;
    const relevantContext = await memory.searchByText(message, 3);
    
    // Build context-aware system prompt
    const contextPrompt = relevantContext.length > 0 
      ? `Context from previous conversations:\n${relevantContext.map(c => c.content).join('\n')}\n\nUser message: ${message}`
      : message;

    return await this.agent.streamChat({
      message: contextPrompt,
      sessionId,
      systemPrompt: `You are a helpful assistant. Use the provided context to give more relevant responses.`,
      onChunk: (chunk) => this.handleChunk(chunk)
    });
  }

  private handleChunk(chunk: string) {
    // Custom chunk processing
    console.log('Processing:', chunk);
  }
}
```

### Multi-Session Agent

Manage multiple conversations simultaneously:

```typescript
class MultiSessionAgent {
  private agent: AgentInstance;
  private activeSessions: Map<string, any> = new Map();

  constructor(agent: AgentInstance) {
    this.agent = agent;
  }

  async startSession(userId: string, topic?: string) {
    const sessionId = `${userId}_${Date.now()}`;
    
    this.activeSessions.set(sessionId, {
      userId,
      topic,
      startTime: new Date(),
      messageCount: 0
    });

    // Send welcome message
    await this.agent.streamChat({
      message: "GREETING_REQUEST",
      sessionId,
      metadata: { userId, topic, type: 'session_start' },
      onChunk: (chunk) => this.broadcastToUser(userId, chunk)
    });

    return sessionId;
  }

  async chatInSession(sessionId: string, message: string) {
    const session = this.activeSessions.get(sessionId);
    if (!session) {
      throw new Error('Session not found');
    }

    session.messageCount++;
    
    return await this.agent.streamChat({
      message,
      sessionId,
      metadata: { 
        userId: session.userId, 
        messageNumber: session.messageCount 
      },
      onChunk: (chunk) => this.broadcastToUser(session.userId, chunk)
    });
  }

  async getSessionSummary(sessionId: string) {
    const history = await this.agent.getHistory(sessionId);
    const session = this.activeSessions.get(sessionId);
    
    return {
      sessionId,
      messageCount: history.length,
      duration: session ? Date.now() - session.startTime.getTime() : 0,
      lastMessage: history[history.length - 1]?.content,
      metadata: session
    };
  }

  private broadcastToUser(userId: string, chunk: string) {
    // Implement WebSocket broadcasting to specific user
    console.log(`To ${userId}:`, chunk);
  }
}
```

### Streaming with Progress Tracking

Track streaming progress and provide feedback:

```typescript
class ProgressTrackingAgent {
  private agent: AgentInstance;

  constructor(agent: AgentInstance) {
    this.agent = agent;
  }

  async streamWithProgress(message: string, sessionId: string, onProgress?: (progress: number) => void) {
    let totalChunks = 0;
    let processedChunks = 0;
    const chunks: string[] = [];

    const response = await this.agent.streamChat({
      message,
      sessionId,
      onChunk: (chunk) => {
        totalChunks++;
        chunks.push(chunk);
        
        // Estimate progress (rough approximation)
        const estimatedTotal = Math.max(totalChunks * 1.2, 10);
        const progress = Math.min((totalChunks / estimatedTotal) * 100, 95);
        
        if (onProgress) {
          onProgress(progress);
        }
        
        console.log(`Progress: ${progress.toFixed(1)}% - Chunk: ${chunk}`);
      }
    });

    // Final progress
    if (onProgress) {
      onProgress(100);
    }

    return {
      response,
      chunks,
      totalChunks,
      averageChunkSize: chunks.join('').length / chunks.length
    };
  }
}
```

## Error Handling and Resilience

Implement robust error handling for streaming chat:

```typescript
class ResilientAgent {
  private agent: AgentInstance;
  private maxRetries = 3;

  constructor(agent: AgentInstance) {
    this.agent = agent;
  }

  async resilientStreamChat(message: string, sessionId: string, onChunk?: (chunk: string) => void) {
    let attempt = 0;
    
    while (attempt < this.maxRetries) {
      try {
        return await this.agent.streamChat({
          message,
          sessionId,
          onChunk: (chunk) => {
            try {
              if (onChunk) onChunk(chunk);
            } catch (chunkError) {
              console.error('Chunk processing error:', chunkError);
            }
          }
        });
      } catch (error) {
        attempt++;
        console.error(`Attempt ${attempt} failed:`, error);
        
        if (attempt >= this.maxRetries) {
          // Fallback to non-streaming
          console.log('Falling back to non-streaming chat');
          return await this.agent.chat({ message, sessionId });
        }
        
        // Wait before retry
        await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
      }
    }
  }
}
```

## Migration from Chat Managers

If you're migrating from the old chat manager approach:

```typescript
// ❌ Old Chat Manager Approach
const chatManager = await createChat({ database, memory });
const response = await chatManager.chat({
  chatId,
  agentId,
  userId,
  message,
  provider,
  systemPrompt
});

// ✅ New Agent-Centric Approach
const agent = await createAgent({ provider, memory });
const response = await agent.streamChat({
  message,
  sessionId: chatId, // chatId becomes sessionId
  systemPrompt,
  onChunk: (chunk) => console.log(chunk) // Real-time streaming
});
```

## Best Practices

1. **Use Streaming**: Always prefer `streamChat()` for better user experience
2. **Consistent Session IDs**: Use meaningful, consistent session identifiers
3. **Error Handling**: Implement proper error handling for network issues
4. **Progress Feedback**: Show streaming progress to users
5. **Memory Management**: Regularly clean old sessions to manage storage
6. **Metadata Usage**: Store relevant metadata for session organization
7. **WebSocket Integration**: Use WebSockets for real-time frontend updates
8. **Fallback Strategy**: Have non-streaming fallback for error scenarios

The agent-centric chat system provides a more streamlined, powerful approach to conversational AI with real-time capabilities built-in. 